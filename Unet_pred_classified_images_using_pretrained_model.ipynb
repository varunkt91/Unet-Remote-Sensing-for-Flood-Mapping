{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flood Map Prediction Using a Trained U-Net Model and Input Raster SAR Data\n",
    "This notebook demonstrates the process of predicting flood maps using a pre-trained U-Net model and input raster SAR (Synthetic Aperture Radar) data. Specifically, Sentinel-1 SAR data is utilized to predict surface water and flooded areas.\n",
    "\n",
    "The steps are as follows:\n",
    "\n",
    "1. Load the Pre-Trained U-Net Model: The first step is to load the trained U-Net model, which will be used for making predictions.\n",
    "\n",
    "2. Import and Preprocess Sentinel-1 SAR Data: The input SAR data (in .tif format) is loaded, and the image is divided into smaller 256x256 pixel chunks, each containing 4 bands. These chunks are generated because the U-Net model was trained on 256x256 pixel images with 4 bands (corresponding to the Sentinel-1 radar channels). This preprocessing step ensures that the input data is compatible with the model's requirements.\n",
    "\n",
    "3. Predict Flood Areas: The preprocessed Sentinel-1 image chunks are passed through the trained U-Net model to predict water/flooded pixels. The model generates a classified output for each chunk, indicating flooded and non-flooded areas. These predicted chunks are then saved in a separate folder.\n",
    "\n",
    "4. Reconstruct the Flood Map: The classified chunks are mosaicked together to reconstruct the final flood map, which represents the predicted surface water and flooded regions over the area covered by the input SAR data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Unet trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(r'D:\\BD_flood_upscale_data\\trained_model.h5', custom_objects={'iou_score': sm.metrics.IOUScore(threshold=0.5)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the input SAR data (in .tif format) , and divide the image into smaller 256x256 pixel chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from rasterio.plot import reshape_as_image\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Parameters\n",
    "root_directory = r'D:\\Khulna_test_floods'  # Root directory containing the images\n",
    "output_directory = r'D:\\khulna_test_flood_chunks'  # Directory to save the chunks\n",
    "patch_size = 256  # Define the patch size for each chunk\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Initialize an empty dataset list\n",
    "image_dataset = []\n",
    "\n",
    "# Walk through the root directory to find images\n",
    "for path, subdirs, files in os.walk(root_directory):\n",
    "    dirname = path.split(os.path.sep)[-1]\n",
    "    \n",
    "    # Check if the folder is 'Images'\n",
    "    if dirname == 'Images':\n",
    "        images = [f for f in files if f.endswith(\".tif\")]\n",
    "        \n",
    "        for image_name in images:\n",
    "            with rasterio.open(os.path.join(path, image_name)) as src:\n",
    "                width = src.width\n",
    "                height = src.height\n",
    "                profile = src.profile  # Get the profile for saving\n",
    "                \n",
    "                # Loop over the image dimensions to create chunks\n",
    "                for row in range(0, height, patch_size):\n",
    "                    for col in range(0, width, patch_size):\n",
    "                        # Define a window for the chunk\n",
    "                        window = Window(col, row, min(patch_size, width - col), min(patch_size, height - row))\n",
    "                        image_data = src.read(window=window)\n",
    "                        image_data = reshape_as_image(image_data)\n",
    "                        \n",
    "                        # Process only if the chunk is the correct size\n",
    "                        if image_data.shape[0] == patch_size and image_data.shape[1] == patch_size:\n",
    "                            # Scale the image data\n",
    "                            image_data_scaled = scaler.fit_transform(image_data.reshape(-1, image_data.shape[-1])).reshape(image_data.shape)\n",
    "                            image_dataset.append(image_data_scaled)\n",
    "                            \n",
    "                            # Update profile for saving each chunk\n",
    "                            profile.update({\n",
    "                                \"height\": patch_size,\n",
    "                                \"width\": patch_size,\n",
    "                                \"transform\": rasterio.windows.transform(window, src.transform),\n",
    "                                \"dtype\": 'float32',  # Assuming we want to save in 8-bit format\n",
    "                                \"count\": image_data.shape[2]  # Number of channels\n",
    "                            })\n",
    "                            \n",
    "                            # Save each chunked image\n",
    "                            output_path = os.path.join(output_directory, f\"{image_name}_chunk_{row}_{col}.tif\")\n",
    "                            with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "                                dst.write((image_data_scaled * 255).astype(np.uint8).transpose(2, 0, 1))  # Convert to 8-bit format for saving\n",
    "                            \n",
    "                            print(f\"Saved chunk at: {output_path}\")\n",
    "\n",
    "# Convert image_dataset to numpy array if needed\n",
    "image_dataset = np.array(image_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLY LOADED UNET MODEL on Sentinel-1 SAR chuncks to predict water and non water class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import rasterio\n",
    "from rasterio.plot import reshape_as_image\n",
    "import segmentation_models as sm\n",
    "\n",
    "# Parameters\n",
    "input_folder = r'D:\\khulna_test_flood_chunks'  # Folder with input image chunks\n",
    "output_folder = r'D:\\predicted_images'  # Folder to save individual predicted images\n",
    "IMG_HEIGHT = 256  # Model input height (and chunk height)\n",
    "IMG_WIDTH = 256   # Model input width (and chunk width)\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load the saved model with custom IOU score\n",
    "model = load_model(r'D:\\BD_flood_upscale_data\\trained_model.h5', custom_objects={'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "# Retrieve chunk files in input folder\n",
    "chunk_files = [f for f in os.listdir(input_folder) if f.endswith('.tif')]\n",
    "\n",
    "# Process each chunk, apply prediction, and save the predicted mask as an individual image\n",
    "for image_file in chunk_files:\n",
    "    try:\n",
    "        # Load the image chunk\n",
    "        with rasterio.open(os.path.join(input_folder, image_file)) as src:\n",
    "            image_data = src.read()  # Read image data\n",
    "            image_data = reshape_as_image(image_data)  # Reshape to (height, width, channels)\n",
    "            \n",
    "            # Resize the image to model input size\n",
    "            image_resized = tf.image.resize(image_data, (IMG_HEIGHT, IMG_WIDTH))\n",
    "            image_resized = np.expand_dims(image_resized, axis=0)  # Add batch dimension\n",
    "            \n",
    "            # Predict the mask\n",
    "            predicted_mask = model.predict(image_resized)\n",
    "            predicted_mask_classes = np.argmax(predicted_mask, axis=-1).squeeze()  # Get the class with the highest score\n",
    "\n",
    "            # Ensure the predicted mask is of type 'uint8' for saving\n",
    "            predicted_mask_classes = predicted_mask_classes.astype(np.uint8)\n",
    "\n",
    "            # Debugging: Print shape of predicted mask to verify\n",
    "            print(f\"Predicted mask shape for {image_file}: {predicted_mask_classes.shape}\")\n",
    "\n",
    "        # Construct the output file path for the predicted mask\n",
    "        output_file_path = os.path.join(output_folder, f'predicted_{image_file}')\n",
    "\n",
    "        # Use metadata from the original chunk for geospatial info\n",
    "        with rasterio.open(os.path.join(input_folder, image_file)) as src:\n",
    "            profile = src.profile\n",
    "            profile.update(\n",
    "                driver='GTiff',\n",
    "                count=1,  # Single band for mask\n",
    "                dtype='uint8',  # Changed from 'byte' to 'uint8'\n",
    "                compress='lzw'  # Compression for output file\n",
    "            )\n",
    "\n",
    "        # Save the predicted mask as a new TIFF file\n",
    "        with rasterio.open(output_file_path, 'w', **profile) as dst:\n",
    "            dst.write(predicted_mask_classes, 1)  # Write the mask to the first band\n",
    "            print(f\"Saved predicted mask for {image_file} to {output_file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_file}: {e}\")\n",
    "\n",
    "print(f\"All predicted images saved in {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECOMBINE predicited classified images to reconstruct classified image (MOSAIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.plot import reshape_as_image\n",
    "from rasterio.windows import Window\n",
    "\n",
    "# Parameters\n",
    "input_directory = r'D:\\predicted_images'  # Directory containing the image chunks\n",
    "output_image_path = r'D:\\recombined_image.tif'  # Path to save the recombined image\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "\n",
    "def mosaic_rasters(input_folder, output_file):\n",
    "    # Use glob to find all .tif files in the input folder\n",
    "    tif_files = glob.glob(os.path.join(input_folder, \"*.tif\"))\n",
    "    \n",
    "    # Open all the raster files\n",
    "    src_files_to_mosaic = []\n",
    "    for tif_file in tif_files:\n",
    "        src = rasterio.open(tif_file)\n",
    "        src_files_to_mosaic.append(src)\n",
    "\n",
    "    # Merge the rasters\n",
    "    mosaic, out_transform = merge(src_files_to_mosaic)\n",
    "\n",
    "    # Get metadata of the first raster (to keep the same for the output)\n",
    "    out_meta = src_files_to_mosaic[0].meta.copy()\n",
    "\n",
    "    # Update metadata with the new size, transform, and CRS\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"count\": mosaic.shape[0],  # Number of bands\n",
    "        \"width\": mosaic.shape[2],  # Width of the mosaic\n",
    "        \"height\": mosaic.shape[1], # Height of the mosaic\n",
    "        \"transform\": out_transform\n",
    "    })\n",
    "\n",
    "    # Write the mosaic to the output file\n",
    "    with rasterio.open(output_file, \"w\", **out_meta) as dest:\n",
    "        dest.write(mosaic)\n",
    "\n",
    "    # Close the source rasters\n",
    "    for src in src_files_to_mosaic:\n",
    "        src.close()\n",
    "\n",
    "# Example usage\n",
    "mosaic_rasters(input_directory, output_image_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
